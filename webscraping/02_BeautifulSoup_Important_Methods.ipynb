{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd2fdeb",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup: Important Methods\n",
    "This notebook provides examples of important methods in BeautifulSoup (`bs4`) for web scraping tasks. Each method is demonstrated with code examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25128288",
   "metadata": {},
   "source": [
    "## 1. `find` and `find_all`\n",
    "**Description**: These methods are used to find elements by their tag name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ae3353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an introductory paragraph.\n",
      "This is an introductory paragraph.\n",
      "This is another paragraph.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"content\">\n",
    "            <h1>Welcome to the Site</h1>\n",
    "            <p class=\"intro\">This is an introductory paragraph.</p>\n",
    "            <p>This is another paragraph.</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the first <p> tag\n",
    "first_paragraph = soup.find('p')\n",
    "print(first_paragraph.text)  # Output: This is an introductory paragraph.\n",
    "\n",
    "# Find all <p> tags\n",
    "all_paragraphs = soup.find_all('p')\n",
    "for p in all_paragraphs:\n",
    "    print(p.text)\n",
    "# Output:\n",
    "# This is an introductory paragraph.\n",
    "# This is another paragraph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f2a4a",
   "metadata": {},
   "source": [
    "## 2. `find_by_class` and `find_all_by_class`\n",
    "**Description**: Find elements by their CSS class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed93d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an introductory paragraph.\n",
      "This is an introductory paragraph.\n"
     ]
    }
   ],
   "source": [
    "# Find the first element with the class 'intro'\n",
    "first_intro = soup.find(class_='intro')\n",
    "print(first_intro.text)  # Output: This is an introductory paragraph.\n",
    "\n",
    "# Find all elements with the class 'intro'\n",
    "all_intro = soup.find_all(class_='intro')\n",
    "for intro in all_intro:\n",
    "    print(intro.text)\n",
    "# Output:\n",
    "# This is an introductory paragraph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdd732",
   "metadata": {},
   "source": [
    "## 3. `find_by_id`\n",
    "**Description**: Find an element by its ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bf68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header Content\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div id=\"header\">Header Content</div>\n",
    "        <div id=\"footer\">Footer Content</div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the element with id 'header'\n",
    "header = soup.find(id='header')\n",
    "print(header.text)  # Output: Header Content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea42e7",
   "metadata": {},
   "source": [
    "## 4. `select` and `select_one`\n",
    "**Description**: Use CSS selectors to find elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c809ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n",
      "/about\n",
      "/home\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            <a href=\"/home\">Home</a>\n",
    "            <a href=\"/about\">About</a>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Select all <a> tags within a div with class 'container'\n",
    "links = soup.select('div.container a')\n",
    "for link in links:\n",
    "    print(link['href'])\n",
    "# Output:\n",
    "# /home\n",
    "# /about\n",
    "\n",
    "# Select the first <a> tag within a div with class 'container'\n",
    "first_link = soup.select_one('div.container a')\n",
    "print(first_link['href'])  # Output: /home\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e8e0f",
   "metadata": {},
   "source": [
    "## 5. `get` Method\n",
    "**Description**: Retrieve the value of an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3320860b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com\n",
      "Example Site\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <a href=\"https://example.com\" title=\"Example Site\">Visit Example</a>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the <a> tag and get the 'href' attribute\n",
    "link = soup.find('a')\n",
    "href_value = link.get('href')\n",
    "print(href_value)  # Output: https://example.com\n",
    "\n",
    "# Get the 'title' attribute\n",
    "title_value = link.get('title')\n",
    "print(title_value)  # Output: Example Site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba70d85",
   "metadata": {},
   "source": [
    "## 6. Navigating the Parse Tree\n",
    "**Description**: Navigate through elements using parent, children, siblings, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367de516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content']\n",
      "Second paragraph.\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"content\">\n",
    "            <h1>Title</h1>\n",
    "            <p>First paragraph.</p>\n",
    "            <p>Second paragraph.</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the first <p> tag\n",
    "first_paragraph = soup.find('p')\n",
    "\n",
    "# Get parent element\n",
    "parent_div = first_paragraph.parent\n",
    "print(parent_div['class'])  # Output: ['content']\n",
    "\n",
    "# Get next sibling (next <p> tag)\n",
    "next_paragraph = first_paragraph.find_next_sibling('p')\n",
    "print(next_paragraph.text)  # Output: Second paragraph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327a629",
   "metadata": {},
   "source": [
    "## 7. `get_text` Method\n",
    "**Description**: Extract all text from an element, including from nested tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0d7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Title \n",
      " First paragraph. \n",
      " Second paragraph. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"content\">\n",
    "            <h1>Title</h1>\n",
    "            <p>First paragraph.</p>\n",
    "            <p>Second paragraph.</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Extract all text from the div with class 'content'\n",
    "content_text = soup.find('div', class_='content').get_text(separator=' ')\n",
    "print(content_text)\n",
    "# Output:\n",
    "# Title First paragraph. Second paragraph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef4d53",
   "metadata": {},
   "source": [
    "## 8. `attrs` Method\n",
    "**Description**: Get all attributes of an element as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7735c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://example.com', 'title': 'Example Site', 'class': ['link']}\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <a href=\"https://example.com\" title=\"Example Site\" class=\"link\">Visit Example</a>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the <a> tag and get all its attributes\n",
    "link = soup.find('a')\n",
    "attributes = link.attrs\n",
    "print(attributes)\n",
    "# Output: {'href': 'https://example.com', 'title': 'Example Site', 'class': ['link']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea881381",
   "metadata": {},
   "source": [
    "## 9. Using Regular Expressions\n",
    "**Description**: Use regex to match tags, attributes, or text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6479e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com/page1\n",
      "https://example.com/page2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <a href=\"https://example.com/page1\">Link 1</a>\n",
    "        <a href=\"https://example.com/page2\">Link 2</a>\n",
    "        <a href=\"/internal/page3\">Internal Link</a>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find all <a> tags with href starting with 'https'\n",
    "external_links = soup.find_all('a', href=re.compile(r'^https://'))\n",
    "for link in external_links:\n",
    "    print(link['href'])\n",
    "# Output:\n",
    "# https://example.com/page1\n",
    "# https://example.com/page2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
